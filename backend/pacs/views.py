# pacs/views.py

from django.conf import settings
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
import requests
import logging
import pydicom
import io
import uuid
from datetime import datetime
from openmrs_integration.models import OpenMRSPatient
from django.http import HttpResponse, JsonResponse # HttpResponse, JsonResponse import ì¶”ê°€

from django.shortcuts import get_object_or_404 # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
from google.cloud import storage # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
from openmrs_integration.models import OpenMRSPatient # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
from django.http import Http404 # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
import tempfile # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
import os # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
import nibabel as nib # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
from rest_framework.parsers import MultiPartParser, FormParser # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
from pydicom.dataset import FileDataset, FileMetaDataset # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
from pydicom.uid import ExplicitVRLittleEndian, generate_uid # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
from datetime import datetime # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
from ai_segmentation_service.segmentation_flow import process_nifti_segmentation # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´
from collections import defaultdict # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´ nnunetì„±ê³µì´í›„ì¶”ê°€
import shutil # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´ nnunetì„±ê³µì´í›„ì¶”ê°€
import numpy as np # ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´ nnunetì„±ê³µì´í›„ì¶”ê°€

import threading
import time
from django.core.cache import cache
from django.shortcuts import render
from django.http import StreamingHttpResponse
from .dicom_seg_converter import SegDicomConverterMixin

# from highdicom.seg.content import SegmentDescription, AlgorithmIdentificationSequence
# from highdicom.seg.sop import Segmentation

logger = logging.getLogger(__name__)
ORTHANC_AUTH = (settings.ORTHANC_USERNAME, settings.ORTHANC_PASSWORD)


class DicomUploadView(APIView):
    """ìƒˆë¡œìš´ DICOM íŒŒì¼ì„ Orthancì— ì—…ë¡œë“œí•˜ëŠ” API (UID êµì²´ ë¡œì§ ìˆ˜ì •)"""
    def post(self, request, format=None):
        logger.info("DicomUploadView: POST ìš”ì²­ ìˆ˜ì‹ ")

        file = request.FILES.get('dicom_file')
        patient_identifier_from_request = request.data.get('patient_identifier')
        patient_uuid_from_request = request.data.get('patient_uuid')
        
        if not file:
            logger.warning("DicomUploadView: ìš”ì²­ì— 'dicom_file' ì—†ìŒ")
            return Response({'error': 'DICOM íŒŒì¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}, status=status.HTTP_400_BAD_REQUEST)
        
        if not patient_identifier_from_request and not patient_uuid_from_request:
            logger.warning("DicomUploadView: í™˜ì ì‹ë³„ìê°€ ì œê³µë˜ì§€ ì•ŠìŒ")
            return Response({'error': 'DICOM ì—°ê´€ì„ ìœ„í•´ í™˜ì ì‹ë³„ìê°€ í•„ìš”í•©ë‹ˆë‹¤'}, status=status.HTTP_400_BAD_REQUEST)

        logger.info(f"DicomUploadView: í™˜ì identifier {patient_identifier_from_request} ë˜ëŠ” UUID {patient_uuid_from_request}ì— ëŒ€í•œ íŒŒì¼ '{file.name}' ì²˜ë¦¬ ì‹œì‘")

        try:
            dicom_bytes = file.read()
            dataset = pydicom.dcmread(io.BytesIO(dicom_bytes))
            logger.info(f"DicomUploadView: DICOM íŒŒì¼ ì½ê¸° ì„±ê³µ. Modality: {getattr(dataset, 'Modality', 'N/A')}")

            patient_instance = None
            try:
                if patient_identifier_from_request:
                    patient_instance = OpenMRSPatient.objects.get(identifier=patient_identifier_from_request)
                    logger.info(f"DicomUploadView: Found patient by identifier: {patient_identifier_from_request}")
                elif patient_uuid_from_request:
                    patient_instance = OpenMRSPatient.objects.get(uuid=patient_uuid_from_request)
                    logger.info(f"DicomUploadView: Found patient by UUID: {patient_uuid_from_request}")
                
                if patient_identifier_from_request:
                    dataset.PatientID = patient_identifier_from_request
                    logger.info(f"DicomUploadView: Set PatientID to frontend identifier: {dataset.PatientID}")
                elif patient_instance and patient_instance.identifier:
                    dataset.PatientID = patient_instance.identifier
                    logger.info(f"DicomUploadView: Set PatientID to Django Patient Identifier: {dataset.PatientID}")
                else:
                    fallback_id = str(patient_instance.uuid).replace('-', '') if patient_instance else str(uuid.uuid4()).replace('-', '')[:8].upper()
                    dataset.PatientID = fallback_id
                    logger.warning(f"DicomUploadView: Using fallback PatientID: {dataset.PatientID}")
                
                if patient_instance and patient_instance.display_name:
                    patient_name_for_dicom = patient_instance.display_name.replace(' ', '^')
                else:
                    patient_name_for_dicom = f"UNKNOWN^PATIENT ({dataset.PatientID})"
                dataset.PatientName = patient_name_for_dicom
                logger.info(f"DicomUploadView: Set PatientName to: {dataset.PatientName}")

            except OpenMRSPatient.DoesNotExist:
                logger.warning(f"DicomUploadView: Patient not found in Django DB. Generating generic PatientID/Name.")
                if not hasattr(dataset, 'PatientID') or not dataset.PatientID:
                    dataset.PatientID = str(uuid.uuid4()).replace('-', '')[:8].upper()
                    logger.info(f"DicomUploadView: Generated generic PatientID: {dataset.PatientID}")
                if not hasattr(dataset, 'PatientName') or not dataset.PatientName:
                    dataset.PatientName = "GENERATED^PATIENT"
                    logger.info("DicomUploadView: Added generic PatientName.")

            logger.info("UID ê¸¸ì´ ê²€ì‚¬ ë° í•„ìš”í•œ ê²½ìš° ì¬ ìƒì„± ì‹œì‘")
            MAX_UID_LENGTH = 64

            try:
                if len(dataset.StudyInstanceUID) > MAX_UID_LENGTH:
                    logger.warning(f"ê¸°ì¡´ StudyInstanceUIDê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤({len(dataset.StudyInstanceUID)}ì). ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    raise AttributeError("UID too long and needs replacement")
            except AttributeError:
                dataset.StudyInstanceUID = pydicom.uid.generate_uid()
                logger.info(f"ìƒˆë¡œìš´ StudyInstanceUID ìƒì„±: {dataset.StudyInstanceUID}")

            try:
                if len(dataset.SeriesInstanceUID) > MAX_UID_LENGTH:
                    logger.warning(f"ê¸°ì¡´ SeriesInstanceUIDê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤({len(dataset.SeriesInstanceUID)}ì). ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    raise AttributeError("UID too long and needs replacement")
            except AttributeError:
                dataset.SeriesInstanceUID = pydicom.uid.generate_uid()
                logger.info(f"ìƒˆë¡œìš´ SeriesInstanceUID ìƒì„±: {dataset.SeriesInstanceUID}")
                
            dataset.SOPInstanceUID = pydicom.uid.generate_uid()
            logger.info(f"ìƒˆë¡œìš´ SOPInstanceUID ìƒì„±: {dataset.SOPInstanceUID}")

            now = datetime.now()
            if not hasattr(dataset, 'StudyDate'): dataset.StudyDate = now.strftime('%Y%m%d')
            if not hasattr(dataset, 'StudyTime'): dataset.StudyTime = now.strftime('%H%M%S.%f')[:-3]
            if not hasattr(dataset, 'Modality'): dataset.Modality = 'OT' # Other

            modified_dicom_stream = io.BytesIO()
            pydicom.dcmwrite(modified_dicom_stream, dataset, write_like_original=False)
            modified_dicom_bytes = modified_dicom_stream.getvalue()

            orthanc_url = f"{settings.ORTHANC_URL}/instances"
            response = requests.post(orthanc_url, data=modified_dicom_bytes, headers={'Content-Type': 'application/dicom'}, auth=ORTHANC_AUTH)
            response.raise_for_status()
            
            orthanc_patient_id = dataset.PatientID
            verify_url = f"{settings.ORTHANC_URL}/tools/find"
            verify_payload = {"Level": "Patient", "Query": {"PatientID": orthanc_patient_id}}
            verify_response = requests.post(verify_url, json=verify_payload, auth=ORTHANC_AUTH)
            
            if verify_response.status_code != 200 or not verify_response.json():
                logger.error(f"[FATAL] Orthancì— PatientID '{orthanc_patient_id}' ì €ì¥ ì‹¤íŒ¨")
                return Response({
                    'error': 'PACS_ID_SAVE_FAILED',
                    'detail': 'DICOM íŒŒì¼ì€ ì—…ë¡œë“œë˜ì—ˆì§€ë§Œ PatientIDê°€ Orthancì— ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                    'orthanc_response': verify_response.text
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            try:
                if patient_instance:
                    patient_instance.pacs_id = orthanc_patient_id
                    patient_instance.save()
                    logger.info(f"DicomUploadView: Updated patient PACS ID to: {orthanc_patient_id}")
            except Exception as update_error:
                logger.exception(f"DicomUploadView: í™˜ì ì •ë³´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")

            return Response(response.json(), status=status.HTTP_201_CREATED)

        except Exception as e:
            logger.exception("DicomUploadView: ì—…ë¡œë“œ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜")
            return Response({
                'error': 'UPLOAD_FAILED',
                'detail': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class PatientStudiesView(APIView):
    """
    íŠ¹ì • í™˜ìì˜ DICOM studies ì¡°íšŒ API - ê¸°ì¡´ ë¡œì§ì„ ìœ ì§€í•˜ë©° Series ì •ë³´ ì¡°íšŒë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    def get(self, request, patient_pacs_id, format=None):
        logger.info(f"PatientStudiesView: GET ìš”ì²­ ìˆ˜ì‹  - patient_pacs_id: {patient_pacs_id}")
        
        if not patient_pacs_id:
            return Response({'error': 'í™˜ì PACS IDê°€ í•„ìš”í•©ë‹ˆë‹¤'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            orthanc_find_url = f"{settings.ORTHANC_URL}/tools/find"
            find_patient_payload = {
                "Level": "Patient",
                "Query": {"PatientID": patient_pacs_id}
            }
            find_patient_response = requests.post(orthanc_find_url, json=find_patient_payload, auth=ORTHANC_AUTH, timeout=10)
            find_patient_response.raise_for_status()
            patient_orthanc_ids = find_patient_response.json()

            if not patient_orthanc_ids:
                logger.warning(f"PACSì—ì„œ í™˜ì ID '{patient_pacs_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return Response({'studies': [], 'message': 'í™˜ìë¥¼ PACSì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}, status=status.HTTP_200_OK)

            find_studies_payload = {
                "Level": "Study",
                "Query": {"PatientID": patient_pacs_id}
            }
            find_studies_response = requests.post(orthanc_find_url, json=find_studies_payload, auth=ORTHANC_AUTH, timeout=10)
            find_studies_response.raise_for_status()
            study_orthanc_ids = find_studies_response.json()

            if not study_orthanc_ids:
                logger.info(f'í™˜ì "{patient_pacs_id}"ì˜ ì˜ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
                return Response({'studies': [], 'message': f'í™˜ì "{patient_pacs_id}"ì˜ ì˜ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}, status=status.HTTP_200_OK)

            studies_data_to_return = []
            for study_id in study_orthanc_ids:
                try:
                    study_url = f"{settings.ORTHANC_URL}/studies/{study_id}"
                    study_response = requests.get(study_url, auth=ORTHANC_AUTH, timeout=10)
                    study_response.raise_for_status()
                    study_data = study_response.json()

                    series_list = []
                    series_url = f"{settings.ORTHANC_URL}/studies/{study_id}/series"
                    series_response = requests.get(series_url, auth=ORTHANC_AUTH, timeout=10)
                    if series_response.status_code == 200:
                        series_list = series_response.json()
                        for series in series_list:
                            series_detail_url = f"{settings.ORTHANC_URL}/series/{series['ID']}"
                            series_detail_response = requests.get(series_detail_url, auth=ORTHANC_AUTH, timeout=10)
                            if series_detail_response.status_code == 200:
                                series.update(series_detail_response.json())

                    study_data['Series'] = series_list
                    
                    public_orthanc_url = settings.ORTHANC_PUBLIC_URL
                    if public_orthanc_url:
                        study_data['viewer_url'] = f"{public_orthanc_url}/app/explorer.html#study?uuid={study_id}"

                    studies_data_to_return.append(study_data)
                    
                except Exception as study_error:
                    logger.warning(f"PatientStudiesView: Study {study_id} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {study_error}")
                    continue

            return Response({"studies": studies_data_to_return}, status=status.HTTP_200_OK)

        except requests.exceptions.RequestException as e:
            logger.error(f"PatientStudiesView: Orthanc í†µì‹  ì˜¤ë¥˜ - {e}")
            return Response({'error': 'ORTHANC_CONNECTION_ERROR', 'detail': str(e)}, status=status.HTTP_503_SERVICE_UNAVAILABLE)
            
        except Exception as e:
            logger.exception("PatientStudiesView: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ")
            return Response({'error': 'INTERNAL_ERROR', 'detail': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            
class VerifyPacsIdView(APIView):
    """PACS ID ì¡´ì¬ ì—¬ë¶€ í™•ì¸ API (ìƒì„¸ ë””ë²„ê¹… ë²„ì „)"""
    def get(self, request, pacs_id, format=None):
        logger.info(f"[VERIFY] PACS ID ê²€ì¦ ì‹œì‘: {pacs_id}")
        
        debug_info = {
            'request_pacs_id': pacs_id,
            'pacs_id_length': len(pacs_id),
            'contains_hyphens': '-' in pacs_id,
            'orthanc_url': settings.ORTHANC_URL,
            'orthanc_public_url': settings.ORTHANC_PUBLIC_URL,
            'timestamp': datetime.now().isoformat()
        }
        
        try:
            # 1. Orthanc ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸
            ping_url = f"{settings.ORTHANC_URL}/system"
            logger.info(f"[VERIFY] Orthanc ì„œë²„ ì—°ê²° í™•ì¸: {ping_url}")
            
            ping_response = requests.get(ping_url, auth=ORTHANC_AUTH, timeout=10)
            if ping_response.status_code != 200:
                logger.error(f"[VERIFY] Orthanc ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {ping_response.status_code}")
                return Response({
                    'error': 'ORTHANC_CONNECTION_FAILED',
                    'detail': f'Orthanc ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {ping_response.status_code}',
                    'debug_info': debug_info
                }, status=status.HTTP_503_SERVICE_UNAVAILABLE)
            
            orthanc_system_info = ping_response.json()
            debug_info['orthanc_system'] = orthanc_system_info
            logger.info(f"[VERIFY] Orthanc ì‹œìŠ¤í…œ ì •ë³´: {orthanc_system_info}")
            
            # 2. ì „ì²´ í™˜ì ëª©ë¡ í™•ì¸
            all_patients_url = f"{settings.ORTHANC_URL}/patients"
            all_patients_response = requests.get(all_patients_url, auth=ORTHANC_AUTH, timeout=10)
            all_patients = all_patients_response.json()
            debug_info['total_patients_in_orthanc'] = len(all_patients)
            logger.info(f"[VERIFY] Orthanc ì „ì²´ í™˜ì ìˆ˜: {len(all_patients)}")
            
            # 3. ì •í™•í•œ PatientID ê²€ìƒ‰
            orthanc_search_url = f"{settings.ORTHANC_URL}/tools/find"
            payload = {
                "Level": "Patient",
                "Query": {"PatientID": pacs_id}
            }
            
            logger.info(f"[VERIFY] ê²€ìƒ‰ ìš”ì²­: {orthanc_search_url}")
            logger.info(f"[VERIFY] ê²€ìƒ‰ í˜ì´ë¡œë“œ: {payload}")
            
            search_response = requests.post(
                orthanc_search_url, 
                json=payload, 
                auth=ORTHANC_AUTH,
                timeout=10
            )
            search_response.raise_for_status()
            
            found_patients = search_response.json(); # ì´ ë¶€ë¶„ì—ì„œ responseê°€ [] ì¼ìˆ˜ë„, [{ID: '...', Type: 'Patient'}] ì¼ìˆ˜ë„ ìˆìŒ
            exists = len(found_patients) > 0
            
            debug_info.update({
                'search_payload': payload,
                'search_response_status': search_response.status_code,
                'found_patients_count': len(found_patients),
                'found_patients_ids': found_patients
            })
            
            logger.info(f"[VERIFY] ê²€ìƒ‰ ê²°ê³¼: {len(found_patients)}ê°œ í™˜ì ë°œê²¬")
            
            # 4. ìœ ì‚¬í•œ PatientID ê²€ìƒ‰ (í•˜ì´í”ˆ ì œê±° ë²„ì „)
            if not exists and '-' in pacs_id:
                cleaned_pacs_id = pacs_id.replace('-', '')
                cleaned_payload = {
                    "Level": "Patient",
                    "Query": {"PatientID": cleaned_pacs_id}
                }
                
                logger.info(f"[VERIFY] í•˜ì´í”ˆ ì œê±° í›„ ì¬ê²€ìƒ‰: {cleaned_pacs_id}")
                cleaned_search_response = requests.post(
                    orthanc_search_url, 
                    json=cleaned_payload, 
                    auth=ORTHANC_AUTH,
                    timeout=10
                )
                cleaned_found_patients = cleaned_search_response.json()
                
                debug_info['cleaned_search'] = {
                    'cleaned_pacs_id': cleaned_pacs_id,
                    'found_patients_count': len(cleaned_found_patients),
                    'found_patients_ids': cleaned_found_patients
                }
            
            # 5. OpenMRS í™˜ì ì •ë³´ í™•ì¸
            try:
                openmrs_patient = OpenMRSPatient.objects.filter(
                    uuid=pacs_id
                ).first()
                if openmrs_patient:
                    debug_info['openmrs_patient'] = {
                        'uuid': str(openmrs_patient.uuid),
                        'identifier': openmrs_patient.identifier,
                        'display_name': openmrs_patient.display_name,
                        'pacs_id': openmrs_patient.pacs_id
                    }
                else:
                    # identifierë¡œë„ ê²€ìƒ‰
                    openmrs_patient_by_id = OpenMRSPatient.objects.filter(
                        identifier=pacs_id
                    ).first()
                    if openmrs_patient_by_id:
                        debug_info['openmrs_patient'] = {
                            'found_by': 'identifier',
                            'uuid': str(openmrs_patient_by_id.uuid),
                            'identifier': openmrs_patient_by_id.identifier,
                            'display_name': openmrs_patient_by_id.display_name,
                            'pacs_id': openmrs_patient_by_id.pacs_id
                        }
            except Exception as openmrs_error:
                debug_info['openmrs_error'] = str(openmrs_error)
                logger.warning(f"[VERIFY] OpenMRS í™˜ì ì¡°íšŒ ì‹¤íŒ¨: {openmrs_error}")
            
            return Response({
                'pacs_id': pacs_id,
                'exists_in_pacs': exists,
                'orthanc_response': found_patients,
                'debug_info': debug_info,
                'recommendations': self._get_recommendations(debug_info, exists)
            }, status=status.HTTP_200_OK)
            
        except requests.exceptions.ConnectionError as e:
            logger.error(f"[VERIFY] Orthanc ì—°ê²° ì˜¤ë¥˜: {e}")
            return Response({
                'error': 'ORTHANC_CONNECTION_ERROR',
                'detail': f'Orthanc ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}',
                'debug_info': debug_info
            }, status=status.HTTP_503_SERVICE_UNAVAILABLE)
            
        except requests.exceptions.Timeout as e:
            logger.error(f"[VERIFY] Orthanc ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {e}")
            return Response({
                'error': 'ORTHANC_TIMEOUT',
                'detail': f'Orthanc ì„œë²„ ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤: {str(e)}',
                'debug_info': debug_info
            }, status=status.HTTP_504_GATEWAY_TIMEOUT)
            
        except requests.exceptions.HTTPError as e:
            logger.error(f"[VERIFY] Orthanc HTTP ì˜¤ë¥˜: {e.response.status_code} - {e.response.text}")
            return Response({
                'error': 'ORTHANC_HTTP_ERROR',
                'detail': f'Orthanc HTTP ì˜¤ë¥˜: {e.response.status_code}',
                'orthanc_response': e.response.text,
                'debug_info': debug_info
            }, status=e.response.status_code)
            
        except Exception as e:
            logger.exception(f"[VERIFY] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ")
            return Response({
                'error': 'VERIFICATION_FAILED',
                'detail': str(e),
                'error_type': type(e).__name__,
                'debug_info': debug_info
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _get_recommendations(self, debug_info, exists):
        """ë””ë²„ê¹… ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ê²° ë°©ì•ˆ ì œì‹œ"""
        recommendations = []
        
        if not exists:
            recommendations.append("PACS IDê°€ Orthancì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            if debug_info.get('contains_hyphens'):
                recommendations.append("í•˜ì´í”ˆì´ í¬í•¨ëœ UUIDì…ë‹ˆë‹¤. í•˜ì´í”ˆì„ ì œê±°í•œ í˜•íƒœë¡œ DICOM PatientIDê°€ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            
            if debug_info.get('total_patients_in_orthanc', 0) == 0:
                recommendations.append("Orthancì— í™˜ì ë°ì´í„°ê°€ ì „í˜€ ì—†ìŠµë‹ˆë‹¤. DICOM íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            
            if 'openmrs_patient' not in debug_info:
                recommendations.append("OpenMRSì—ì„œ í•´ë‹¹ í™˜ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™˜ì ë“±ë¡ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            else:
                openmrs_data = debug_info['openmrs_patient']
                if openmrs_data.get('identifier'):
                    recommendations.append(f"OpenMRS í™˜ìì˜ identifierëŠ” '{openmrs_data['identifier']}'ì…ë‹ˆë‹¤. ì´ ê°’ìœ¼ë¡œ DICOMì´ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        
        return recommendations


# ìƒˆë¡­ê²Œ ì¶”ê°€ëœ DICOM ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜
def get_dicom_instance_data(request, instance_id):
    """
    Orthancë¡œë¶€í„° íŠ¹ì • DICOM ì¸ìŠ¤í„´ìŠ¤ íŒŒì¼ì˜ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ì§ì ‘ ê°€ì ¸ì™€ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    """
    logger.info(f"get_dicom_instance_data: ìš”ì²­ ìˆ˜ì‹  - instance_id: {instance_id}")

    orthanc_url = settings.ORTHANC_URL
    orthanc_auth = (settings.ORTHANC_USERNAME, settings.ORTHANC_PASSWORD)

    # Orthancì—ì„œ íŠ¹ì • ì¸ìŠ¤í„´ìŠ¤ì˜ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” API ì—”ë“œí¬ì¸íŠ¸
    # Orthanc REST API ë¬¸ì„œ: /instances/{id}/file
    orthanc_instance_file_url = f"{orthanc_url}/instances/{instance_id}/file"

    try:
        response = requests.get(orthanc_instance_file_url, auth=orthanc_auth, stream=True, timeout=30)
        response.raise_for_status() # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ (4xx, 5xx)

        # ì‘ë‹µ í—¤ë” ì„¤ì •: CornerstoneJSê°€ DICOM íŒŒì¼ì„ì„ ì¸ì‹í•˜ë„ë¡ Content-Type ì„¤ì •ì´ ì¤‘ìš”
        # ë˜í•œ, Content-Dispositionì„ ì„¤ì •í•˜ì—¬ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œ íŒŒì¼ ì´ë¦„ì„ ì§€ì •í•  ìˆ˜ ìˆìŒ
        response_headers = {
            'Content-Type': 'application/dicom', # í‘œì¤€ DICOM MIME íƒ€ì…
            'Content-Disposition': f'attachment; filename="{instance_id}.dcm"'
        }

        # Orthancë¡œë¶€í„° ë°›ì€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ìŠ¤íŠ¸ë¦¬ë°
        # chunk_sizeë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ìš©ëŸ‰ íŒŒì¼ë„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬
        logger.info(f"get_dicom_instance_data: Orthancì—ì„œ ì¸ìŠ¤í„´ìŠ¤ {instance_id} ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘. Status: {response.status_code}")
        return HttpResponse(response.iter_content(chunk_size=8192), headers=response_headers, status=response.status_code)

    except requests.exceptions.RequestException as e:
        logger.error(f"get_dicom_instance_data: Orthanc í†µì‹  ì˜¤ë¥˜ ë˜ëŠ” íŒŒì¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ - Instance ID: {instance_id}, Error: {e}")
        # DRF Response ëŒ€ì‹  Djangoì˜ JsonResponseë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€ (ì„ íƒ ì‚¬í•­)
        return JsonResponse({"error": f"PACSì—ì„œ DICOM íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    except Exception as e:
        logger.exception(f"get_dicom_instance_data: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ - Instance ID: {instance_id}")
        return JsonResponse({"error": f"ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {e}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class SeriesInstancesView(APIView):
    """íŠ¹ì • ì‹œë¦¬ì¦ˆì˜ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ë¥¼ ì¡°íšŒí•˜ì—¬ Cornerstone.jsê°€ ì‚¬ìš©í•  imageIds ëª©ë¡ì„ ë°˜í™˜"""
    def get(self, request, study_instance_uid, series_instance_uid, format=None):
        logger.info(f"SeriesInstancesView: GET ìš”ì²­ ìˆ˜ì‹  - Study: {study_instance_uid}, Series: {series_instance_uid}")
        
        try:
            # Orthancì˜ REST APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œë¦¬ì¦ˆ ë‚´ì˜ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ ID ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            # ì´ 'instance_id'ëŠ” Orthanc ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•˜ëŠ” UUIDì…ë‹ˆë‹¤.
            instances_url = f"{settings.ORTHANC_URL}/series/{series_instance_uid}/instances" 
            instances_response = requests.get(instances_url, auth=ORTHANC_AUTH, timeout=20)
            instances_response.raise_for_status()
            instances_list_from_orthanc = instances_response.json() # This list contains Orthanc's internal instance UUIDs

            if not instances_list_from_orthanc:
                return Response({"error": "í•´ë‹¹ ì‹œë¦¬ì¦ˆì— ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."}, status=status.HTTP_404_NOT_FOUND)

            image_ids = []
            
            # ë°›ì•„ì˜¨ Orthanc ì¸ìŠ¤í„´ìŠ¤ ID ëª©ë¡ì„ ìˆœíšŒí•©ë‹ˆë‹¤.
            for orthanc_instance_id in instances_list_from_orthanc:
                # Orthancì˜ /series/{series_uid}/instances APIê°€ ë°˜í™˜í•˜ëŠ” ê²ƒì´
                # ì¸ìŠ¤í„´ìŠ¤ UUID ë¬¸ìì—´ë“¤ì˜ ë°°ì—´ì¸ì§€, ì•„ë‹ˆë©´ {ID: '...', Type: 'Instance'}ì™€ ê°™ì€ ê°ì²´ ë°°ì—´ì¸ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
                # ë¡œê·¸ì— ë”°ë¥´ë©´ ê°ì²´ ë°°ì—´ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ orthanc_instance_idì—ì„œ 'ID' ì†ì„±ì„ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
                instance_uuid = orthanc_instance_id # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ë¬¸ìì—´ì´ë¼ê³  ê°€ì •
                
                # â˜…â˜…â˜… ì´ ì¡°ê±´ë¬¸ì„ ì¶”ê°€í•˜ì—¬ orthanc_instance_idê°€ ë”•ì…”ë„ˆë¦¬ì¼ ê²½ìš° 'ID' ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. â˜…â˜…â˜…
                if isinstance(orthanc_instance_id, dict) and 'ID' in orthanc_instance_id:
                    instance_uuid = orthanc_instance_id['ID']
                
                # ì´ instance_uuidëŠ” get_dicom_instance_dataì˜ {instance_id}ì— ì •í™•íˆ ë§¤í•‘ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                dicom_data_proxy_url = request.build_absolute_uri(
                    f'/api/pacs/dicom-instance-data/{instance_uuid}/'
                )
                
                # Cornerstone.jsëŠ” 'wadouri:' í”„ë¦¬í”½ìŠ¤ë¥¼ í†µí•´ ì›Œì»¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
                wadouri_url = f"wadouri:{dicom_data_proxy_url}"
                image_ids.append(wadouri_url)
                logger.debug(f"SeriesInstancesView: Generated imageId: {wadouri_url}")

            if not image_ids:
                return Response({"error": "ìœ íš¨í•œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, status=status.HTTP_404_NOT_FOUND)

            logger.info(f"SeriesInstancesView: {len(image_ids)}ê°œì˜ imageIds ë°˜í™˜")
            return Response(image_ids, status=status.HTTP_200_OK)

        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                logger.warning(f"SeriesInstancesView: Orthancì—ì„œ Study/Series '{study_instance_uid}/{series_instance_uid}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return Response({"error": "Orthancì—ì„œ í•´ë‹¹ Study/Seriesë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, status=status.HTTP_404_NOT_FOUND)
            logger.error(f"SeriesInstancesView: Orthanc HTTP ì˜¤ë¥˜: {e.response.status_code} - {e.response.text}")
            return Response({"error": f"Orthanc ì˜¤ë¥˜: {e.response.text}"}, status=e.response.status_code)
        except Exception as e:
            logger.exception("SeriesInstancesView: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜")
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


# ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´ ì—¬ëŸ¬ê°œ íŒŒì¼ ë™ì‹œì— ì˜¬ë¦¬ëŠ”ê±° êµ¬í˜„ì¤‘
class NiftiUploadView(APIView):
    parser_classes = [MultiPartParser, FormParser]

    def post(self, request, *args, **kwargs):
        patient_uuid = request.data.get('patient_uuid')
        files = request.FILES.getlist('files')
        modalities = request.data.getlist('modalities')

        # --- í•„ë“œ ìœ íš¨ì„± ê²€ì‚¬ ---
        if not patient_uuid:
            return Response({"detail": "patient_uuidê°€ í•„ìš”í•©ë‹ˆë‹¤."}, status=400)
        if not files or not modalities:
            return Response({"detail": "filesì™€ modalitiesë¥¼ í•¨ê»˜ ë³´ë‚´ì•¼ í•©ë‹ˆë‹¤."}, status=400)
        if len(files) != len(modalities):
            return Response({"detail": "filesì™€ modalities ê°œìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤."}, status=400)
        if len(files) > 3:
            return Response({"detail": "ìµœëŒ€ 3ê°œê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."}, status=400)

        # --- í™˜ì ê²€ì¦ ---
        try:
            # ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” OpenMRSPatient ëª¨ë¸ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
            patient = get_object_or_404(OpenMRSPatient, uuid=patient_uuid)
        except Http404:
            return Response({"detail": "í•´ë‹¹ UUIDì˜ í™˜ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, status=404)

        # --- ë¶€ì¡±í•œ ëª¨ë‹¬ë¦¬í‹°ì— ëŒ€í•´ ë”ë¯¸ íŒŒì¼ ì²˜ë¦¬ ì¤€ë¹„ ---
        # ì˜ˆ: modalities=['FLAIR','DWI'] -> files, modalities ë¦¬ìŠ¤íŠ¸ì— ADCì— ëŒ€í•œ í•­ëª© ì¶”ê°€
        all_modalities = ['FLAIR', 'DWI', 'ADC']
        current_modalities = {mod: file for mod, file in zip(modalities, files)}
        
        processed_files = []
        processed_modalities = []

        for mod in all_modalities:
            processed_modalities.append(mod)
            processed_files.append(current_modalities.get(mod)) # í•´ë‹¹ ëª¨ë‹¬ë¦¬í‹°ê°€ ì—†ìœ¼ë©´ Noneì´ ì¶”ê°€ë¨

        # --- ì²˜ë¦¬ ê²°ê³¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ---
        result = []

        # --- ê° íŒŒì¼/ëª¨ë‹¬ë¦¬í‹°ë§ˆë‹¤ ì²˜ë¦¬ ---
        for nifti_file, modality in zip(processed_files, processed_modalities):
            # íŒŒì¼ì´ Noneì´ë©´ ë”ë¯¸ ë°ì´í„°ë¡œ ì²˜ë¦¬
            if nifti_file is None:
                # TODO: ë”ë¯¸ NIfTI ìƒì„± ë˜ëŠ” ìŠ¤í‚µ ë¡œì§ êµ¬í˜„
                result.append({'modality': modality, 'status': 'dummy_generated'})
                continue

            # --- ì‹¤ì œ íŒŒì¼ ì²˜ë¦¬: ì„ì‹œ ì €ì¥ â†’ GCS ì—…ë¡œë“œ â†’ DICOM ë³€í™˜ â†’ Orthanc ì—…ë¡œë“œ ---
            tmp_path = None # finally ë¸”ë¡ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì´ˆê¸°í™”
            try:
                # 1) ì„ì‹œ íŒŒì¼ì— NIfTI ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix='.nii') as tmp:
                    tmp_path = tmp.name
                    for chunk in nifti_file.chunks():
                        tmp.write(chunk)

                # 2) Google Cloud Storageì— ì—…ë¡œë“œ
                storage_client = storage.Client()
                bucket = storage_client.bucket(settings.GCS_BUCKET_NAME)
                # timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
                # blob_name = f"nifti/{patient_uuid}/{modality}/{timestamp}_{os.path.basename(nifti_file.name)}"
                # â”€â”€ ì„¸ì…˜ í´ë” ì´ë¦„ (ì˜ˆ: "20250625_1704") â”€â”€
                session_folder = datetime.now().strftime('%Y%m%d_%H%M')

                # GCS ê²½ë¡œ: nifti/{patient_uuid}/{session_folder}/{modality}/íŒŒì¼ëª…
                blob_name = (
                    f"nifti/{patient_uuid}/"
                    f"{session_folder}/"
                    f"{modality}/"
                    f"{os.path.basename(nifti_file.name)}"
                )                
                bucket.blob(blob_name).upload_from_filename(tmp_path)

                uploaded_blobs[modality.lower()] = f"gs://{settings.GCS_BUCKET_NAME}/{blob_name}"

                # 3) NIfTI íŒŒì¼ì„ DICOMìœ¼ë¡œ ë³€í™˜ ë° Orthanc ì—…ë¡œë“œ
                img = nib.load(tmp_path).get_fdata()
                study_uid = pydicom.uid.generate_uid()
                series_uid = pydicom.uid.generate_uid()

                for i in range(img.shape[2]):
                    slice_data = (img[:, :, i] * 255).astype('uint16')

                    # File Meta ìƒì„±
                    file_meta = FileMetaDataset()
                    file_meta.MediaStorageSOPClassUID    = '1.2.840.10008.5.1.4.1.1.2' # CT Image Storage
                    file_meta.MediaStorageSOPInstanceUID = generate_uid()
                    file_meta.TransferSyntaxUID          = ExplicitVRLittleEndian
                    file_meta.ImplementationClassUID     = generate_uid()

                    # FileDataset ìƒì„±
                    ds = FileDataset("", {}, file_meta=file_meta, preamble=b"\0" * 128)

                    # í•„ìˆ˜ DICOM íƒœê·¸ ì±„ìš°ê¸°
                    ds.PatientID                 = patient.identifier
                    ds.PatientName               = patient.display_name
                    ds.Modality                  = modality
                    ds.StudyInstanceUID          = study_uid
                    ds.SeriesInstanceUID         = series_uid
                    ds.SOPClassUID               = file_meta.MediaStorageSOPClassUID
                    ds.SOPInstanceUID            = file_meta.MediaStorageSOPInstanceUID
                    
                    ds.Rows, ds.Columns          = slice_data.shape
                    ds.SamplesPerPixel           = 1
                    ds.PhotometricInterpretation = "MONOCHROME2"
                    ds.PixelRepresentation       = 0
                    ds.BitsAllocated             = 16
                    ds.BitsStored                = 16
                    ds.HighBit                   = 15
                    ds.PixelData                 = slice_data.tobytes()

                    ds.is_little_endian          = True
                    ds.is_implicit_VR            = False
                    
                    # 4) ìƒì„±ëœ DICOM ìŠ¬ë¼ì´ìŠ¤ë¥¼ Orthancì— ì—…ë¡œë“œ
                    with tempfile.NamedTemporaryFile(suffix='.dcm') as dcm_tmp:
                        ds.save_as(dcm_tmp.name, write_like_original=False)
                        with open(dcm_tmp.name, 'rb') as fp:
                            dicom_bytes = fp.read()

                    resp = requests.post(
                        f"{settings.ORTHANC_URL}/instances",
                        data=dicom_bytes,
                        auth=(settings.ORTHANC_USERNAME, settings.ORTHANC_PASSWORD),
                        headers={'Content-Type': 'application/dicom'}
                    )
                    resp.raise_for_status()

                result.append({'modality': modality, 'status': 'uploaded'})

            except Exception as e:
                result.append({'modality': modality, 'status': 'error', 'error': str(e)})
            
            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                if tmp_path and os.path.exists(tmp_path):
                    os.remove(tmp_path)

        return Response({'results': result}, status=201)


# ####### ìœ ì •ìš°ë„Œí• ìˆ˜ìˆì–´ nnunetì„±ê³µì´í›„ ì¶”ê°€ ###########
# class ListPatientSessionsView(APIView):
#     def get(self, request, patient_uuid, *args, **kwargs):
#         logger.info(f"GCS íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹œì‘. í™˜ì UUID: {patient_uuid}")
#         try:
#             storage_client = storage.Client()
#             bucket = storage_client.bucket("final_model_data1")
#             prefix = f"nifti/{patient_uuid}/"
#             blobs = list(bucket.list_blobs(prefix=prefix))
            
#             if not blobs:
#                 return Response({"sessions": []})

#             sessions_data = defaultdict(lambda: defaultdict(list))
#             for blob in blobs:
#                 parts = blob.name.split('/')
#                 if len(parts) >= 5 and parts[-1]:
#                     session_id, modality, file_name = parts[2], parts[3], parts[4]
#                     sessions_data[session_id][modality.lower()].append({
#                         "name": file_name,
#                         "gcs_path": f"gs://{bucket.name}/{blob.name}",
#                     })
            
#             if not sessions_data: return Response({"sessions": []})

#             formatted_sessions = [{"sessionId": sid, "modalities": mods} for sid, mods in sessions_data.items()]
#             sorted_sessions = sorted(formatted_sessions, key=lambda s: s['sessionId'], reverse=True)
#             return Response({"sessions": sorted_sessions})
#         except Exception as e:
#             logger.error(f"GCS íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
#             return Response({"error": "ì„œë²„ ì˜¤ë¥˜"}, status=500)

class ListPatientSessionsView(APIView):
    def get(self, request, patient_uuid, *args, **kwargs):
        logger.info(f"GCS íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹œì‘. í™˜ì UUID: {patient_uuid}")
        try:
            storage_client = storage.Client()
            # ğŸ’¡ ë²„í‚· ì´ë¦„ì„ settingsì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ í•˜ë“œì½”ë”©ëœ ê°’ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”.
            bucket = storage_client.bucket("final_model_data1") 
            prefix = f"nifti/{patient_uuid}/"
            blobs = list(bucket.list_blobs(prefix=prefix))
            
            if not blobs:
                return Response({"sessions": []})

            sessions_data = defaultdict(lambda: defaultdict(list))
            for blob in blobs:
                # âœ¨ ì„ì‹œ íŒŒì¼ì„ ìƒì„±í•˜ê³  ì‚­ì œí•˜ê¸° ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”
                temp_file_path = None
                try:
                    parts = blob.name.split('/')
                    if len(parts) >= 5 and parts[-1]:
                        session_id, modality, file_name = parts[2], parts[3], parts[4]
                        
                        metadata = {}
                        try:
                            # 1. ê³ ìœ í•œ ì´ë¦„ì„ ê°€ì§„ ì„ì‹œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
                            with tempfile.NamedTemporaryFile(delete=False, suffix=".nii.gz") as tmp_file:
                                temp_file_path = tmp_file.name
                            
                            # 2. GCSì˜ íŒŒì¼ì„ ì´ ì„ì‹œ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
                            blob.download_to_filename(temp_file_path)
                            
                            # 3. ì´ì œ íŒŒì¼ 'ê²½ë¡œ'ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ nib.loadê°€ í™•ì‹¤í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤.
                            nifti_img = nib.load(temp_file_path)
                            
                            shape = nifti_img.shape
                            zooms = nifti_img.header.get_zooms()
                            
                            metadata = {
                                "resolution": f"{shape[0]}x{shape[1]}",
                                "sliceThickness": float(f"{zooms[2]:.2f}")
                            }
                        except Exception as meta_error:
                            logger.warning(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ ({blob.name}): {meta_error}")
                            metadata = {}

                        sessions_data[session_id][modality.lower()].append({
                            "name": file_name,
                            "gcs_path": f"gs://{bucket.name}/{blob.name}",
                            "metadata": metadata
                        })
                except Exception as e:
                    logger.error(f"ì„¸ì…˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({blob.name}): {e}")
                    continue
                finally:
                    # 4. try-except ë¡œì§ì´ ëë‚˜ë©´ í•­ìƒ ì„ì‹œ íŒŒì¼ì„ ì‚­ì œí•˜ì—¬ ì„œë²„ì— ì“°ë ˆê¸° íŒŒì¼ì´ ë‚¨ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
                    if temp_file_path and os.path.exists(temp_file_path):
                        os.remove(temp_file_path)

            if not sessions_data: 
                return Response({"sessions": []})

            formatted_sessions = [{"sessionId": sid, "modalities": mods} for sid, mods in sessions_data.items()]
            sorted_sessions = sorted(formatted_sessions, key=lambda s: s['sessionId'], reverse=True)
            return Response({"sessions": sorted_sessions})
            
        except Exception as e:
            logger.error(f"GCS íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return Response({"error": "ì„œë²„ ì˜¤ë¥˜"}, status=500)

class DicomConverterMixin:
    def convert_nifti_to_dicom(self, gcs_path, patient, study_uid, image_type, request):
        logger.info(f"DICOM ë³€í™˜ ì‹œì‘ ({image_type}): {gcs_path}")
        safe_temp_dir = os.path.join(settings.BASE_DIR, 'temp_files')
        os.makedirs(safe_temp_dir, exist_ok=True)
        temp_nifti_path = os.path.join(safe_temp_dir, f"{uuid.uuid4()}.nii.gz")
        temp_dicom_dir = tempfile.mkdtemp(dir=safe_temp_dir)
        
        try:
            storage_client = storage.Client()
            bucket_name, blob_name = gcs_path.replace("gs://", "").split("/", 1)
            bucket = storage_client.bucket(bucket_name)
            bucket.blob(blob_name).download_to_filename(temp_nifti_path)
            
            nifti_img = nib.load(temp_nifti_path)
            img_data = nifti_img.get_fdata()

            if image_type.upper() == 'SEG':
                # ë§ˆìŠ¤í¬ëŠ” 0/1 or 0/255ë¡œ ê°•ì œ ë³€í™˜ (í”½ì…€ ì˜¤ë²„ë ˆì´ ì„ ëª…í•˜ê²Œ!)
                    img_data = (img_data <= 0.5).astype(np.uint8) * 255   # â˜…â˜…â˜… ë°˜ì „!
                    window_center, window_width = 128, 255
                    real_min, real_max = 0, 255
                    int_max, int_min = 255, 0
                    rescale_slope = 1
                    rescale_intercept = 0
                    bits_allocated = 8
                    bits_stored = 8
                    high_bit = 7
            else:
                window_center, window_width = 115.0, 4186.0
                real_min, real_max = np.min(img_data), np.max(img_data)
                int_max, int_min = np.iinfo(np.int16).max, np.iinfo(np.int16).min
                rescale_slope = (real_max - real_min) / (int_max - int_min) if real_max != real_min else 1.0
                rescale_intercept = real_min

            series_uid = generate_uid()
            orthanc_ids = []

            for i in range(img_data.shape[2]):
                slice_float = img_data[:, :, i]
                scaled_slice = ((slice_float - rescale_intercept) / rescale_slope) + int_min if rescale_slope != 0 else np.zeros_like(slice_float)
                pixel_data, pixel_repr = scaled_slice.astype(np.int16), 1

                rotated_data = np.rot90(pixel_data, k=3)
                ds = FileDataset(None, {}, file_meta=FileMetaDataset(), preamble=b"\0" * 128)
                ds.file_meta.MediaStorageSOPClassUID = pydicom.uid.MRImageStorage
                ds.file_meta.MediaStorageSOPInstanceUID = generate_uid()
                ds.file_meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian
                ds.PatientID, ds.PatientName = patient.identifier, patient.display_name.replace(' ', '^')
                ds.StudyInstanceUID, ds.SeriesInstanceUID = study_uid, series_uid
                ds.SOPInstanceUID, ds.SOPClassUID = ds.file_meta.MediaStorageSOPInstanceUID, ds.file_meta.MediaStorageSOPClassUID
                ds.Modality, ds.InstanceNumber, ds.ImageType = "MR", str(i + 1), ["DERIVED", "PRIMARY"]
                ds.StudyDate, ds.StudyTime = datetime.now().strftime('%Y%m%d'), datetime.now().strftime('%H%M%S')
                pix_zooms = nifti_img.header.get_zooms()[:2]
                ds.PixelSpacing = [f"{z:.8f}" for z in reversed(pix_zooms)]
                ds.Rows, ds.Columns = rotated_data.shape
                ds.SamplesPerPixel = 1
                ds.PhotometricInterpretation = "MONOCHROME2"
                ds.BitsAllocated, ds.BitsStored, ds.HighBit = 16, 16, 15
                ds.PixelRepresentation = pixel_repr
                ds.PixelData = rotated_data.tobytes()
                ds.RescaleIntercept, ds.RescaleSlope = f"{rescale_intercept:.8f}", f"{rescale_slope:.8f}"
                ds.WindowCenter, ds.WindowWidth = f"{window_center:.8f}", f"{window_width:.8f}"
                temp_dcm_path = os.path.join(temp_dicom_dir, f"slice_{i}.dcm")
                ds.save_as(temp_dcm_path, write_like_original=False)
                with open(temp_dcm_path, 'rb') as f:
                    resp = requests.post(f"{settings.ORTHANC_URL}/instances", data=f.read(), auth=ORTHANC_AUTH)
                    resp.raise_for_status()
                    orthanc_ids.append(resp.json()['ID'])
            
            image_ids = [f"wadouri:{request.build_absolute_uri(f'/api/pacs/dicom-instance-data/{_id}/')}" for _id in orthanc_ids]
            return {"seriesInstanceUID": series_uid, "imageIds": image_ids}

        except Exception as e:
            logger.error(f"DICOM ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ({gcs_path}): {e}", exc_info=True)
            return None
        finally:
            if 'temp_nifti_path' in locals() and os.path.exists(temp_nifti_path): os.remove(temp_nifti_path)
            if 'temp_dicom_dir' in locals() and os.path.exists(temp_dicom_dir): shutil.rmtree(temp_dicom_dir)


class NiftiToDicomView(APIView, DicomConverterMixin):
    def post(self, request, *args, **kwargs):
        gcs_path = request.data.get('gcs_path'); patient_uuid = request.data.get('patient_uuid')
        image_type = request.data.get('image_type', 'unknown')
        if not gcs_path or not patient_uuid: return Response({"error": "gcs_path, patient_uuid í•„ìš”"}, status=400)
        
        try:
            # patient = get_object_or_404(OpenMRSPatient, uuid=patient_uuid)
            class TempPatient: identifier = patient_uuid; display_name = "Unknown^Patient"
            patient = TempPatient()
        except (ImportError, Http404):
            class TempPatient: identifier = patient_uuid; display_name = "Unknown^Patient"
            patient = TempPatient()

        result = self.convert_nifti_to_dicom(gcs_path, patient, generate_uid(), image_type, request)
        if result: return Response(result)
        return Response({"error": "DICOM ë³€í™˜ ì„œë²„ ì˜¤ë¥˜"}, status=500)


class NiftiToDicomBundleView(APIView, DicomConverterMixin, SegDicomConverterMixin):
    def post(self, request, *args, **kwargs):
        image_requests = request.data.get('images', [])
        patient_uuid = request.data.get('patient_uuid')
        if not image_requests or not patient_uuid:
            return Response({"error": "images, patient_uuid í•„ìš”"}, status=400)
        try:
            # patient = get_object_or_404(OpenMRSPatient, uuid=patient_uuid)
            class TempPatient: identifier = patient_uuid; display_name = "Unknown^Patient"
            patient = TempPatient()
        except (ImportError, Http404):
            class TempPatient: identifier = patient_uuid; display_name = "Unknown^Patient"
            patient = TempPatient()

        results, study_uid = {}, generate_uid()
        for req in image_requests:
            image_type, gcs_path = req.get('type'), req.get('gcs_path')
            if image_type and gcs_path:
                # ì´ì œ SEGë„ ì¼ë°˜ DICOM ì‹œë¦¬ì¦ˆë¡œ ë³€í™˜
                series_result = self.convert_nifti_to_dicom(
                    gcs_path, patient, study_uid, image_type, request
                )
                if series_result:
                    results[image_type] = series_result
        # for req in image_requests:
        #     image_type, gcs_path = req.get('type'), req.get('gcs_path')
        #     if image_type and gcs_path:
        #         if image_type.upper() == "SEG":
        #             series_result = self.convert_nifti_to_dicom_seg(
        #                 gcs_path, patient, study_uid, request
        #             )
        #         else:
        #             series_result = self.convert_nifti_to_dicom(
        #                 gcs_path, patient, study_uid, image_type, request
        #             )
        #         if series_result:
        #             results[image_type] = series_result

        return Response(results)


class DicomInstanceDataView(APIView):
    authentication_classes, permission_classes = [], []
    def get(self, request, instance_id, *args, **kwargs):
        orthanc_url = f"{settings.ORTHANC_URL}/instances/{instance_id}/file"
        try:
            response = requests.get(orthanc_url, auth=ORTHANC_AUTH, stream=True)
            response.raise_for_status()
            return HttpResponse(response.content, content_type=response.headers['Content-Type'])
        except requests.exceptions.RequestException as e:
            logger.error(f"Orthanc ì¸ìŠ¤í„´ìŠ¤({instance_id}) GET ì˜¤ë¥˜: {e}")
            return Response({"error": "Orthanc ì„œë²„ ë°ì´í„° GET ì‹¤íŒ¨"}, status=502)


class FileDeleteAPIView(APIView):
    """
    GCSì— ìˆëŠ” íŒŒì¼ì„ ì‚­ì œí•˜ëŠ” API
    """
    def delete(self, request, *args, **kwargs):
        # 1. ë¦¬ëª¨ì»¨(í”„ë¡ íŠ¸ì—”ë“œ)ì—ì„œ ë³´ë‚¸ gcs_path ì •ë³´ë¥¼ êº¼ëƒ…ë‹ˆë‹¤.
        gcs_path = request.data.get('gcs_path')

        if not gcs_path:
            return Response(
                {"error": "ì‚­ì œí•  íŒŒì¼ì˜ gcs_pathê°€ í•„ìš”í•©ë‹ˆë‹¤."},
                status=status.HTTP_400_BAD_REQUEST
            )

        try:
            # 2. GCS ê²½ë¡œë¥¼ 'ë²„í‚· ì´ë¦„'ê³¼ 'íŒŒì¼ ì´ë¦„(blob_name)'ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
            if not gcs_path.startswith("gs://"):
                raise ValueError("ì˜¬ë°”ë¥´ì§€ ì•Šì€ GCS ê²½ë¡œ í˜•ì‹ì…ë‹ˆë‹¤.")
            
            parts = gcs_path.replace("gs://", "").split("/", 1)
            bucket_name = parts[0]
            blob_name = parts[1]

            # 3. [í•µì‹¬] GCSì— ì ‘ì†í•˜ì—¬ ì‹¤ì œ íŒŒì¼ì„ ì‚­ì œí•˜ëŠ” ë¡œì§
            # TODO: ì´ ë¶€ë¶„ì€ ì‹¤ì œ GCS í”„ë¡œì íŠ¸ ì„¤ì •ì— ë§ëŠ” ì¸ì¦ ê³¼ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            storage_client = storage.Client()
            bucket = storage_client.bucket(bucket_name)
            blob = bucket.blob(blob_name)

            if not blob.exists():
                return Response(
                    {"error": "GCSì—ì„œ í•´ë‹¹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."},
                    status=status.HTTP_404_NOT_FOUND
                )
            
            # ì‹¤ì œ íŒŒì¼ ì‚­ì œ ëª…ë ¹
            blob.delete()

            print(f"íŒŒì¼ ì‚­ì œ ì„±ê³µ: {gcs_path}")

            # 4. ì„±ê³µì ìœ¼ë¡œ ì„ë¬´ë¥¼ ë§ˆì³¤ìŒì„ ì•Œë¦½ë‹ˆë‹¤.
            return Response(
                {"message": f"íŒŒì¼ '{blob_name}'ì´(ê°€) ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."},
                status=status.HTTP_204_NO_CONTENT # ì„±ê³µ ì‹œì—ëŠ” ë³´í†µ ë‚´ìš© ì—†ì´ ìƒíƒœ ì½”ë“œë§Œ ë³´ëƒ…ë‹ˆë‹¤.
            )

        except Exception as e:
            # 5. ì„ë¬´ ìˆ˜í–‰ ì¤‘ ë¬¸ì œê°€ ìƒê¸°ë©´ ì˜¤ë¥˜ë¥¼ ë³´ê³ í•©ë‹ˆë‹¤.
            print(f"GCS íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return Response(
                {"error": "ì„œë²„ì—ì„œ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

class SessionDeleteAPIView(APIView):
    """
    íŠ¹ì • ì„¸ì…˜ì— ì†í•œ ëª¨ë“  GCS íŒŒì¼ì„ ì‚­ì œí•˜ëŠ” API
    """
    def delete(self, request, *args, **kwargs):
        # 1. ë¦¬ëª¨ì»¨ì—ì„œ ë³´ë‚¸ patient_idì™€ session_id ì •ë³´ë¥¼ êº¼ëƒ…ë‹ˆë‹¤.
        patient_id = request.data.get('patient_id')
        session_id = request.data.get('session_id')

        if not patient_id or not session_id:
            return Response(
                {"error": "patient_idì™€ session_idê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."},
                status=status.HTTP_400_BAD_REQUEST
            )
        
        try:
            # 2. ì‚­ì œí•  í´ë” ê²½ë¡œë¥¼ ë§Œë“­ë‹ˆë‹¤. (ì˜ˆ: "nifti/í™˜ìID/ì„¸ì…˜ID/")
            # TODO: ì´ ë¶€ë¶„ì€ ì‹¤ì œ GCS í´ë” êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            # ì˜ˆì‹œì—ì„œëŠ” 'nifti/' ë¡œ ì‹œì‘í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
            folder_prefix = f"nifti/{patient_id}/{session_id}/"

            # 3. [í•µì‹¬] GCSì— ì ‘ì†í•˜ì—¬ í•´ë‹¹ í´ë” ì•ˆì˜ ëª¨ë“  íŒŒì¼ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
            # TODO: bucket_nameì€ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ë²„í‚· ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
            bucket_name = "final_model_data1" 
            storage_client = storage.Client()
            bucket = storage_client.bucket(bucket_name)
            
            # folder_prefixë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  íŒŒì¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
            blobs_to_delete = list(bucket.list_blobs(prefix=folder_prefix))

            if not blobs_to_delete:
                print(f"ì„¸ì…˜ í´ë”ì— ì‚­ì œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {folder_prefix}")
                # íŒŒì¼ì´ ì—†ì–´ë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                return Response(
                    {"message": "ì‚­ì œí•  íŒŒì¼ì´ ì—†ì§€ë§Œ, ì„¸ì…˜ ì‚­ì œ ì²˜ë¦¬ ì™„ë£Œ."},
                    status=status.HTTP_204_NO_CONTENT
                )

            # 4. [ê¶ŒëŠ¥ í–‰ì‚¬] ì°¾ì•„ë‚¸ ëª¨ë“  íŒŒì¼ì„ í•˜ë‚˜ì”© ì†Œë©¸ì‹œí‚µë‹ˆë‹¤.
            for blob in blobs_to_delete:
                blob.delete()
                print(f"íŒŒì¼ ì‚­ì œ ì„±ê³µ: {blob.name}")

            print(f"ì„¸ì…˜ í´ë” ì „ì²´ ì‚­ì œ ì„±ê³µ: {folder_prefix}")
            
            # 5. ì„ë¬´ ì™„ìˆ˜ë¥¼ ë³´ê³ í•©ë‹ˆë‹¤.
            return Response(
                {"message": f"ì„¸ì…˜ '{session_id}'ì˜ ëª¨ë“  íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."},
                status=status.HTTP_204_NO_CONTENT
            )

        except Exception as e:
            print(f"GCS ì„¸ì…˜ í´ë” ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return Response(
                {"error": "ì„œë²„ì—ì„œ ì„¸ì…˜ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

# [ê°€ìƒ ëª¨ë¸ ì‹¤í–‰ í•¨ìˆ˜] - ì´ ë¶€ë¶„ì€ ì‹¤ì œ ëª¨ë¸ ì‹¤í–‰ ë¡œì§ì— ë§ê²Œ ìˆ˜ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
def run_actual_segmentation_model(task_id, payload):
    total_steps = 10 # ì˜ˆì‹œ: ì´ 10ë‹¨ê³„ì˜ ì‘ì—…
    print(f"ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘: Task {task_id}")
    try:
        # TODO: ì—¬ê¸°ì— ì‹¤ì œ segmentation ë¡œì§ì„ í˜¸ì¶œí•˜ì‹­ì‹œì˜¤.
        # ì˜ˆ: from your_ml_app.tasks import process_segmentation
        # process_segmentation(payload) 
        
        # ì§€ê¸ˆì€ ì§„í–‰ë¥ ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.
        for i in range(total_steps + 1):
            progress = int((i / total_steps) * 100)
            cache.set(task_id, {'status': 'processing', 'progress': progress}, timeout=3600)
            print(f"Task {task_id}: ì§„í–‰ë¥  {progress}%")
            time.sleep(3) # 3ì´ˆ ë”œë ˆì´ë¡œ ì‹¤ì œ ì‘ì—… ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        
        # ì‘ì—… ì™„ë£Œ í›„ ìµœì¢… ìƒíƒœë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        cache.set(task_id, {'status': 'completed', 'progress': 100, 'result': 'some_result_path'}, timeout=3600)
        print(f"Task {task_id}: ì™„ë£Œ")
    except Exception as e:
        print(f"Task {task_id}: ì‹¤íŒ¨ - {e}")
        cache.set(task_id, {'status': 'failed', 'error': str(e)}, timeout=3600)

# ë¶„í•  ì‘ì—…ì„ ì‹œì‘í•˜ëŠ” View
class SegmentationAPIView(APIView):
    def post(self, request, *args, **kwargs):
        payload = request.data
        task_id = str(uuid.uuid4())
        thread = threading.Thread(target=run_actual_segmentation_model, args=(task_id, payload))
        thread.start()
        return Response(
            {"message": "ë¶„í•  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.", "task_id": task_id},
            status=status.HTTP_202_ACCEPTED
        )

# ì‘ì—… ìƒíƒœë¥¼ ë³´ê³ í•˜ëŠ” View
class TaskStatusAPIView(APIView):
    def get(self, request, task_id, *args, **kwargs):
        task_info = cache.get(task_id)
        if task_info is None:
            return Response({"status": "not_found"}, status=status.HTTP_404_NOT_FOUND)
        return Response(task_info, status=status.HTTP_200_OK)


